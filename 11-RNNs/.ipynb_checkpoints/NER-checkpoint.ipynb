{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f2df72",
   "metadata": {},
   "source": [
    "# Named Entity Recognition with Bidirectional LSTM\n",
    "\n",
    "Named Entity Recognition (NER) is similar to POS tagging (using the same many-to-many classification code) except it only tags specific entities like person name, organisation name, country name etc. TensorFlow uses IOB format to tag named entities:\n",
    "\n",
    "    I 'inside' a named chunk of text\n",
    "    O 'outside' a named chunk of text\n",
    "    B 'beginning' a named chunk of text\n",
    "\n",
    "\n",
    "## Set up the data\n",
    "\n",
    "The data is downloaded from the online course in **pickle format**, which is a Python hierarchical object converted to bytes in order to efficiently store large amounts of data. The data has already been split into training and test sets, with each containing the input words (already split) and target named entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f59f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20cdf05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in pickle file to load training data\n",
    "\n",
    "with open('data/ner_train.pkl', 'rb') as f:\n",
    "    corpus_train = pickle.load(f)\n",
    "\n",
    "# Read in pickle file to load test data\n",
    "\n",
    "with open('data/ner_test.pkl', 'rb') as f:\n",
    "    corpus_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b239eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65120c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = []\n",
    "train_targets = []\n",
    "\n",
    "for sentence_tag_pairs in corpus_train:\n",
    "    tokens = [] \n",
    "    target = [] \n",
    "    \n",
    "    for token, tag in sentence_tag_pairs:\n",
    "        tokens.append(token) \n",
    "        target.append(tag) \n",
    "        \n",
    "    train_inputs.append(tokens) \n",
    "    train_targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8851f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = []\n",
    "test_targets = []\n",
    "\n",
    "for sentence_tag_pairs in corpus_test:\n",
    "    tokens = [] \n",
    "    target = [] \n",
    "    \n",
    "    for token, tag in sentence_tag_pairs:\n",
    "        tokens.append(token) \n",
    "        target.append(tag) \n",
    "        \n",
    "    test_inputs.append(tokens) \n",
    "    test_targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b6646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac4b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, Bidirectional\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c8ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- Convert sentences of words to sequences of integers\n",
    "\n",
    "MAX_VOCAB_SIZE = None\n",
    "\n",
    "# Capitalization might be useful - test it\n",
    "should_lowercase = False\n",
    "\n",
    "# Set up tokenizer\n",
    "word_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, lower=should_lowercase, oov_token='UNK')\n",
    "# Otherwise unknown tokens will be removed and len(input) != len(target)\n",
    "# - input words and target words will not be aligned!\n",
    "\n",
    "# It's ok to \"fit\" on the whole corpus - it just means some embeddings won't be trained\n",
    "# This is because for the test set, any unknown tokens will be removed, which will change the length of input (CHECK!!!)\n",
    "word_tokenizer.fit_on_texts(train_inputs)\n",
    "\n",
    "train_inputs_int = word_tokenizer.texts_to_sequences(train_inputs)\n",
    "\n",
    "test_inputs_int = word_tokenizer.texts_to_sequences(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d7ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word -> integer mapping for vocab size (V)\n",
    "\n",
    "word2idx = word_tokenizer.word_index\n",
    "\n",
    "V = len(word2idx)\n",
    "\n",
    "print('Found %s unique tokens.' % V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f183055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to flatten list of lists to a single list\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    flattened = [val for sublist in list_of_lists for val in sublist] \n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58746b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that targets match in training and test sets\n",
    "\n",
    "all_train_targets = set(flatten(train_targets))\n",
    "\n",
    "all_train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71550d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_targets = set(flatten(test_targets))\n",
    "\n",
    "all_test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca56e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_targets == all_test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d479ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------- Convert lists of targets to sequences of integers\n",
    "\n",
    "tag_tokenizer = Tokenizer()\n",
    "\n",
    "tag_tokenizer.fit_on_texts(train_targets)\n",
    "\n",
    "train_targets_int = tag_tokenizer.texts_to_sequences(train_targets)\n",
    "test_targets_int = tag_tokenizer.texts_to_sequences(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a812b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for later use in SciKit-Learn performance metrics (without padding)\n",
    "\n",
    "train_targets_int_unpadded = train_targets_int\n",
    "test_targets_int_unpadded = test_targets_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e732e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before padding, find max sequence length (T) since we don't want to truncate any inputs which would also truncate targets\n",
    "\n",
    "maxlen_train = max(len(sent) for sent in train_inputs)\n",
    "maxlen_test = max(len(sent) for sent in test_inputs)\n",
    "\n",
    "T = max((maxlen_train, maxlen_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------- Pad sequences to get N x T matrix\n",
    "\n",
    "train_inputs_int = pad_sequences(train_inputs_int, maxlen=T)\n",
    "\n",
    "print('Shape of data train tensor:', train_inputs_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda44b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs_int = pad_sequences(test_inputs_int, maxlen=T)\n",
    "\n",
    "print('Shape of data test tensor:', test_inputs_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d4b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets_int = pad_sequences(train_targets_int, maxlen=T)\n",
    "\n",
    "print('Shape of train targets tensor:', train_targets_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca5a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets_int = pad_sequences(test_targets_int, maxlen=T)\n",
    "\n",
    "print('Shape of test targets tensor:', test_targets_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e835fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------- Number of classes\n",
    "\n",
    "K = len(tag_tokenizer.word_index) + 1\n",
    "\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e4280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ Create the model\n",
    "\n",
    "# You choose embedding dimensionality\n",
    "D = 32\n",
    "\n",
    "# Note: You actually want size of the embedding matrix to be (V + 1) x D, because the first index starts from 1 and not 0.\n",
    "# Thus, if the final index of the embedding matrix is V, then it actually must have size V + 1.\n",
    "\n",
    "i = Input(shape=(T,))\n",
    "\n",
    "# mask_zero=True way slower on GPU than CPU!\n",
    "x = Embedding(V + 1, D, mask_zero=True)(i)\n",
    "\n",
    "x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
    "# x = SimpleRNN(32, return_sequences=True)(x)\n",
    "\n",
    "x = Dense(K)(x)\n",
    "\n",
    "model = Model(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aeabab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "model.compile(loss=SparseCategoricalCrossentropy(from_logits=True), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16251ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model (60 secs per epoch on CPU)\n",
    "\n",
    "print('Training model...')\n",
    "\n",
    "r = model.fit(train_inputs_int, train_targets_int, epochs=5, validation_data=(test_inputs_int, test_targets_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d818e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss per epoch\n",
    "\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy per epoch\n",
    "\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b5c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- True model accuracy - below includes unpadded targets\n",
    "\n",
    "# Get length of each sequence in training and test sets\n",
    "\n",
    "train_lengths = []\n",
    "\n",
    "for sentence in train_inputs:\n",
    "    train_lengths.append(len(sentence))\n",
    "\n",
    "test_lengths = []\n",
    "\n",
    "for sentence in test_inputs:\n",
    "    test_lengths.append(len(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf1a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from training set\n",
    "train_probs = model.predict(train_inputs_int) # N x T x K\n",
    "\n",
    "# Access label with highest probabilty and remove padding\n",
    "train_predictions = []\n",
    "\n",
    "for probs, length in zip(train_probs, train_lengths):\n",
    "    # probs is T x K \n",
    "    probs_ = probs[-length:] \n",
    "    preds = np.argmax(probs_, axis=1) \n",
    "    train_predictions.append(preds)\n",
    "\n",
    "# Flatten for use in SciKit\n",
    "flat_train_predictions = flatten(train_predictions)\n",
    "\n",
    "flat_train_targets = flatten(train_targets_int_unpadded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09857101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from test set\n",
    "test_probs = model.predict(test_inputs_int) # N x T x K\n",
    "\n",
    "# Access labels with highest probability and remove padding\n",
    "test_predictions = []\n",
    "\n",
    "for probs, length in zip(test_probs, test_lengths):\n",
    "    # probs is T x K \n",
    "    probs_ = probs[-length:] \n",
    "    preds = np.argmax(probs_, axis=1) \n",
    "    test_predictions.append(preds)\n",
    "\n",
    "# Flatten for use in SciKit\n",
    "flat_test_predictions = flatten(test_predictions)\n",
    "\n",
    "flat_test_targets = flatten(test_targets_int_unpadded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f6056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print(\"Train acc:\", accuracy_score(flat_train_targets, flat_train_predictions))\n",
    "print(\"Test acc:\", accuracy_score(flat_test_targets, flat_test_predictions))\n",
    "\n",
    "print(\"Train f1:\", f1_score(flat_train_targets, flat_train_predictions, average='macro'))\n",
    "print(\"Test f1:\", f1_score(flat_test_targets, flat_test_predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f437812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------- Baseline model: map word to tag\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Function to find the most common element in a list\n",
    "\n",
    "def most_common(lst):\n",
    "    data = Counter(lst) \n",
    "    return data.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee700c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2tags = {k: [] for k, v in word2idx.items()}\n",
    "\n",
    "# remove UNK token\n",
    "del token2tags['UNK']\n",
    "\n",
    "# Map words to tokens\n",
    "for tokens, tags in zip(train_inputs, train_targets):\n",
    "    for token, tag in zip(tokens, tags):\n",
    "        if should_lowercase:\n",
    "            token = token.lower() \n",
    "            \n",
    "        if token in token2tags:\n",
    "            token2tags[token].append(tag)\n",
    "\n",
    "# Print\n",
    "for k, v in token2tags.items():\n",
    "    if len(v) == 0:\n",
    "        print(k)\n",
    "\n",
    "\n",
    "token2tag = {k: most_common(v) for k, v in token2tags.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94267cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy from training set\n",
    "\n",
    "train_predictions = []\n",
    "\n",
    "for sentence in train_inputs:\n",
    "    predictions = [] \n",
    "    \n",
    "    for token in sentence:\n",
    "        if should_lowercase:\n",
    "            token = token.lower() \n",
    "            \n",
    "        predicted_tag = token2tag[token] \n",
    "        predictions.append(predicted_tag) \n",
    "            \n",
    "    train_predictions.append(predictions)\n",
    "            \n",
    "# Flatten for use in SciKit\n",
    "flat_train_predictions = flatten(train_predictions)\n",
    "flat_train_targets = flatten(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adfbcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy from test set\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "for sentence in test_inputs:\n",
    "    predictions = [] \n",
    "    \n",
    "    for token in sentence:\n",
    "        predicted_tag = token2tag.get(token, 'INCORRECT') \n",
    "        predictions.append(predicted_tag) \n",
    "        \n",
    "    test_predictions.append(predictions)\n",
    "    \n",
    "# Flatten for use in SciKit\n",
    "flat_test_predictions = flatten(test_predictions)\n",
    "flat_test_targets = flatten(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train acc:\", accuracy_score(flat_train_targets, flat_train_predictions))\n",
    "print(\"Test acc:\", accuracy_score(flat_test_targets, flat_test_predictions))\n",
    "\n",
    "print(\"Train f1:\", f1_score(flat_train_targets, flat_train_predictions, average='macro'))\n",
    "print(\"Test f1:\", f1_score(flat_test_targets, flat_test_predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c74878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d1731e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
