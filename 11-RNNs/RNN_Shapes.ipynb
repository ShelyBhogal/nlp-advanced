{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dfebd3a",
   "metadata": {},
   "source": [
    "# RNN Shapes through the network\n",
    "\n",
    "It helps to track the 'shape' of the data through the RNN network to understand what is happening under-the-hood. Understanding the mathematics is not as important as knowing the flow of the information.\n",
    "\n",
    "For example, whenever you hear ***N* x *T* x *D*** matrix, you should think of a box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fad5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3965af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1fa1fd",
   "metadata": {},
   "source": [
    "## Things you should know\n",
    "\n",
    "Below are the important size variables, whose meaning should be permanently stored in your memory!\n",
    "\n",
    "* **N** number of samples\n",
    "* **T** sequence length\n",
    "* **D** number of input features\n",
    "* **M** number of hidden neurons\n",
    "* **K** number of neurons in outer dense layer\n",
    "\n",
    "Lets make some synthetic three-dimensional data of univariate continuous random values taken from a normal distribution, for a simple RNN regression (no activation function required in outer layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "162b0c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set size variables\n",
    "N = 1\n",
    "T = 10\n",
    "D = 3\n",
    "K = 2\n",
    "\n",
    "# Fake data\n",
    "X = np.random.randn(N, T, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357aca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make regression RNN network\n",
    "\n",
    "M = 5\n",
    "\n",
    "i = Input(shape=(T, D)) # (10 x 3)\n",
    "\n",
    "x = SimpleRNN(M)(i)\n",
    "\n",
    "x = Dense(K)(x)\n",
    "\n",
    "model = Model(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a1b9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 146ms/step\n",
      "[[-0.0652515 -0.1478728]]\n"
     ]
    }
   ],
   "source": [
    "# Get predicted output (1 x 2, i.e. one sample and two output results)\n",
    "\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ec3fb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 3)]           0         \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 5)                 45        \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# View model structure\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de430c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.15654248, -0.5145449 , -0.16511536, -0.70954716, -0.13775456],\n",
       "        [ 0.2526881 , -0.35481632,  0.05409688,  0.0730921 , -0.04302329],\n",
       "        [ 0.72688645,  0.7206072 , -0.33525246, -0.45841673, -0.6241146 ]],\n",
       "       dtype=float32),\n",
       " array([[ 0.72892296, -0.25976282, -0.52256536, -0.318251  , -0.16381761],\n",
       "        [ 0.22756657,  0.8399016 , -0.2946632 ,  0.3781304 , -0.11388477],\n",
       "        [-0.5640798 , -0.01988399, -0.4627396 , -0.17590362, -0.6605669 ],\n",
       "        [-0.16779234,  0.42310807, -0.0911424 , -0.78809524,  0.40425766],\n",
       "        [-0.26560187, -0.2183408 , -0.64626944,  0.32202098,  0.6003509 ]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the weights - there are three arrays of weights for each of the three layers\n",
    "\n",
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ef8d675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5) (5, 5) (5,)\n"
     ]
    }
   ],
   "source": [
    "# Print out shape of weight arrays - remember that D=3 and M=5\n",
    "\n",
    "a, b, c = model.layers[1].get_weights()\n",
    "\n",
    "print(a.shape, b.shape, c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b04858",
   "metadata": {},
   "source": [
    "**Note that these shapes should make sense:**\n",
    "\n",
    "    a is input weight by hidden weight (D x M)\n",
    "\n",
    "    b is hidden weight by hidden weight (M x M)\n",
    "\n",
    "    c is bias term (vector of length M)\n",
    "    \n",
    "**Now you can assign the 'weight' variables with *confidence*.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9666a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and hidden weights\n",
    "Wx, Wh, bh = model.layers[1].get_weights()\n",
    "\n",
    "# Outer layer weights\n",
    "Wo, bo = model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c63d6581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5) (5, 5) (5,)\n",
      "(5, 2) (2,)\n"
     ]
    }
   ],
   "source": [
    "print(Wx.shape, Wh.shape, bh.shape)\n",
    "\n",
    "print(Wo.shape, bo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d7f4c",
   "metadata": {},
   "source": [
    "## Manual RNN calculation\n",
    "\n",
    "Using For Loop, run a single sample (x) through the calculations that are performed under-the-hood of a simple RNN model:\n",
    "\n",
    "    h = np.tanh(x[t].dot(Wx) + h_last.dot(Wh) + bh)\n",
    "    y = h.dot(Wo) + bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "637cc6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0652515  -0.14787285]\n"
     ]
    }
   ],
   "source": [
    "# Initial hidden state\n",
    "h_last = np.zeros(M)\n",
    "\n",
    "# One and only sample\n",
    "x = X[0]\n",
    "\n",
    "# Store outputs\n",
    "yhats = []\n",
    "\n",
    "for t in range(T):\n",
    "    # Calculate hidden value at hidden layer\n",
    "    h = np.tanh(x[t].dot(Wx) + h_last.dot(Wh) + bh)\n",
    "    y = h.dot(Wo) + bo\n",
    "    yhats.append(y)\n",
    "    \n",
    "    # NB: Assign h to h_last so it has correct value for next iteration\n",
    "    h_last = h\n",
    "\n",
    "# We only care about final yhat value\n",
    "print(yhats[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f35a156",
   "metadata": {},
   "source": [
    "**Compare to model's prediction of -0.0652515 and -0.1478728...it is exactly the same! This is what you wanted. You have confirmed that these are the calculations done in a simple RNN (with one sample only).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c5841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Modify code to run multiple samples at once, i.e. N > 1 \n",
    "# The code should produce the same result even when you have multiple samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
