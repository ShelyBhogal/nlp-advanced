{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a56a0a0d",
   "metadata": {},
   "source": [
    "# Text Classifier\n",
    "\n",
    "Use the Markov principles to build a text classifier that can identify the lines of an unknown poem as belonging to either Edgar Allan Poe or Robert Frost.\n",
    "\n",
    "Lines of poems belonging to both authors have been saved to separate text files in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02430e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c089d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f44943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LO! Death hath rear'd himself a throne\\n\", 'In a strange city, all alone,\\n', 'Far down within the dim west\\n', 'Where the good, and the bad, and the worst, and the best,\\n', 'Have gone to their eternal rest.\\n', 'â€‰\\n', 'There shrines, and palaces, and towers\\n', 'Are not like any thing of ours\\n', 'Oh no! O no! ours never loom\\n', 'To heaven with that ungodly gloom!\\n', 'Time-eaten towers that tremble not!\\n', 'Resemble nothing that is ours.\\n', 'Around, by lifting winds forgot,\\n', 'Resignedly beneath the sky\\n', 'The melancholy waters lie.\\n', 'â€‰\\n', 'No holy rays from heaven come down\\n', 'On the long night-time of that town,\\n', 'But light from out the lurid sea\\n', 'Streams up the turrets silently\\n']\n"
     ]
    }
   ],
   "source": [
    "# View the head of text files\n",
    "\n",
    "with open('data/edgar_allan_poe.txt') as input_file: \n",
    "    head = [next(input_file) for _ in range(20)]\n",
    "\n",
    "print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8759291e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Two roads diverged in a yellow wood,\\n', 'And sorry I could not travel both\\n', 'And be one traveler, long I stood\\n', 'And looked down one as far as I could\\n', 'To where it bent in the undergrowth; \\n', '\\n', 'Then took the other, as just as fair,\\n', 'And having perhaps the better claim\\n', 'Because it was grassy and wanted wear,\\n', 'Though as for that the passing there\\n', 'Had worn them really about the same,\\n', '\\n', 'And both that morning equally lay\\n', 'In leaves no step had trodden black.\\n', 'Oh, I kept the first for another day! \\n', 'Yet knowing how way leads on to way\\n', 'I doubted if I should ever come back.\\n', '\\n', 'I shall be telling this with a sigh\\n', 'Somewhere ages and ages hence:\\n']\n"
     ]
    }
   ],
   "source": [
    "with open('data/robert_frost.txt') as input_file: \n",
    "    head = [next(input_file) for _ in range(20)]\n",
    "\n",
    "print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd95c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that each line is terminated with '\\n' character (new line) - use .rstrip() to remove\n",
    "# Note that some lines are empty (â€‰ is single quotation mark)\n",
    "# Note that there are capitals and lower-case letters - use .lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03326833",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = ['data/edgar_allan_poe.txt', 'data/robert_frost.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "634a3c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/edgar_allan_poe.txt corresponds to label 0\n",
      "data/robert_frost.txt corresponds to label 1\n"
     ]
    }
   ],
   "source": [
    "input_texts = []\n",
    "labels = []\n",
    "\n",
    "# enumerate() assigns an index number at the same time\n",
    "for label, f in enumerate(input_files): \n",
    "    print(f\"{f} corresponds to label {label}\") \n",
    "    \n",
    "    # This will only run if line is not empty\n",
    "    for line in open(f): \n",
    "        line = line.rstrip().lower() \n",
    "        \n",
    "        if line: \n",
    "            # Remove punctuation (taken from StackOverflow)\n",
    "            line = line.translate(str.maketrans('', '', string.punctuation)) \n",
    "            input_texts.append(line) \n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74e58b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lo death hath reard himself a throne',\n",
       " 'in a strange city all alone',\n",
       " 'far down within the dim west',\n",
       " 'where the good and the bad and the worst and the best',\n",
       " 'have gone to their eternal rest',\n",
       " 'â€‰',\n",
       " 'there shrines and palaces and towers',\n",
       " 'are not like any thing of ours',\n",
       " 'oh no o no ours never loom',\n",
       " 'to heaven with that ungodly gloom']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hmmm...those 'â€‰' lines are still there...\n",
    "\n",
    "input_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e022a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i.e. top half belongs to Edgar Allan Poe, so lines appear in the order in which files were processed\n",
    "\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48a18187",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, y_train, y_test = train_test_split(input_texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2af84794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1618, 540)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f8f35c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to go west to a worse fight with the desert',\n",
       " 'that made him throw his bare legs out of bed',\n",
       " 'oh fly let us fly for we must',\n",
       " 'were not too much to pay for birth',\n",
       " 'wherever the ground was low and wet',\n",
       " 'and the smell of fire drowned in rain',\n",
       " 'no fãªte today he said',\n",
       " 'they left the named',\n",
       " 'to tell the truth suppose the time had come',\n",
       " 'something i must have learned riding in trains']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Order of lines and labels now mixed up\n",
    "\n",
    "train_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4453c29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a37e5f1",
   "metadata": {},
   "source": [
    "## Convert lines of text to lines of integers\n",
    "\n",
    "You must create a **word-to-index mapping** dictionary that holds the index number for each word. These indices are used to replace the words when converting the text to numbers. The dictionary is built using the training data only, since you would not have access to the test set in the real world.\n",
    "\n",
    "NOTE: You should always assign an index for unknown words that will be introduced in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a9db91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acts as counter index as you loop through the words/tokens, i.e. current index\n",
    "idx = 1\n",
    "\n",
    "# Intialize word-to-index mapping dictionary with special index in place for unknown words\n",
    "word2idx = {'<unk>': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ef6fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through training text and populate word2idx mapping\n",
    "\n",
    "for text in train_text: \n",
    "    # Split text into tokens, i.e. words\n",
    "    tokens = text.split() \n",
    "    \n",
    "    for token in tokens: \n",
    "        if token not in word2idx: \n",
    "            word2idx[token] = idx \n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cdd77da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx['snow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b26812c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2491"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will determine the size of Markov matrix (2491x2491), as well as vocabulary size\n",
    "\n",
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14367760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all text lines into integer lines with word2idx mapping replacing the words\n",
    "\n",
    "train_text_int = []\n",
    "test_text_int = []\n",
    "\n",
    "# Loop through training set\n",
    "for text in train_text: \n",
    "    tokens = text.split() \n",
    "    line_as_int = [word2idx[token] for token in tokens] \n",
    "    train_text_int.append(line_as_int)\n",
    "\n",
    "# Loop through test set - need to account for unknown words, i.e. assign 0\n",
    "for text in test_text: \n",
    "    tokens = text.split() \n",
    "    # Get token index or return 0\n",
    "    line_as_int = [word2idx.get(token, 0) for token in tokens] \n",
    "    test_text_int.append(line_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21d46569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[37, 378, 8, 379, 18, 8, 19, 380, 67],\n",
       " [42, 370, 381, 382, 18, 8, 383],\n",
       " [8, 384, 136, 385, 18, 386, 387, 37, 388],\n",
       " [274, 389, 1, 108, 390, 391, 392],\n",
       " [18, 393, 7, 394, 100, 395]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each number in list corresponds to a word\n",
    "\n",
    "train_text_int[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b509893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[37, 1488, 100, 168, 0, 1, 2360],\n",
       " [756, 275, 42, 8, 0, 0, 18, 233],\n",
       " [1658, 1571, 1659, 876],\n",
       " [357, 59, 484, 1985],\n",
       " [8, 0, 1578, 8, 0, 1149, 362]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_int[100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db3d93",
   "metadata": {},
   "source": [
    "## Setting up the `A` matrix and `pi` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a386be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of words\n",
    "V = len(word2idx)\n",
    "\n",
    "# Initialize A and pi matrices for both models representing each category (Poe model | Frost model)\n",
    "# All matrices and arrays initialized with 1s to use add-one smoothing\n",
    "\n",
    "A0 = np.ones((V, V))\n",
    "pi0 = np.ones(V)\n",
    "\n",
    "A1 = np.ones((V, V))\n",
    "pi1 = np.ones(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63dfe96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to compute word counts for A and pi for a single Markov model, i.e. single category\n",
    "# Input list of integers and arrays to be populated\n",
    "\n",
    "def compute_counts(text_as_int, A, pi): \n",
    "    # Loop through each line of integers\n",
    "    for tokens in text_as_int: \n",
    "        # No index for previous word - this helps to know whether you are dealing with A or pi\n",
    "        last_idx = None \n",
    "        \n",
    "        for idx in tokens: \n",
    "            if last_idx is None: \n",
    "                # If previous word is None, it's the first word in a sentence and populate pi\n",
    "                pi[idx] += 1 \n",
    "            else: \n",
    "                # The previous word exists so count as transition from one word to the next and populate A\n",
    "                A[last_idx, idx] += 1 \n",
    "                \n",
    "            # Update last idx to current idx so it has correct value for next iteration\n",
    "            last_idx = idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fca00d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate matrices with word count probability distributions\n",
    "compute_counts([t for t, y in zip(train_text_int, y_train) if y == 0], A0, pi0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e1603ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_counts([t for t, y in zip(train_text_int, y_train) if y == 1], A1, pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf340e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output objects are the populated A and pi matrices for both Poe and Frost models\n",
    "A0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd3dbed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., 38.,  1., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38cc4ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize A and pi so they go from counts to probability matrices\n",
    "# keepdims=True ensures that the 2-dimensions are kept for the output (pi is 1D-array so no need)\n",
    "\n",
    "A0 /= A0.sum(axis=1, keepdims=True)\n",
    "pi0 /= pi0.sum()\n",
    "\n",
    "A1 /= A1.sum(axis=1, keepdims=True)\n",
    "pi1 /= pi1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c984f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find log A and pi since we don't need the actual probability values\n",
    "\n",
    "logA0 = np.log(A0)\n",
    "logpi0 = np.log(pi0)\n",
    "\n",
    "logA1 = np.log(A1)\n",
    "logpi1 = np.log(pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcad8a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE CLASS BALANCE STATISTICS\n",
    "\n",
    "# How many samples belong to class 0 and 1 in training set?\n",
    "count0 = sum(y == 0 for y in y_train)\n",
    "count1 = sum(y == 1 for y in y_train)\n",
    "\n",
    "total = len(y_train)\n",
    "\n",
    "# Calculate proportions of each class in training set\n",
    "p0 = count0 / total\n",
    "p1 = count1 / total\n",
    "\n",
    "# Calculate logs probabilities of each class in training set - these are the 'log priors' to use in classifier\n",
    "logp0 = np.log(p0)\n",
    "logp1 = np.log(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49880c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.323238566131026, 0.676761433868974)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is approx 34% Edgar vs 66% Frost - quite imbalanced dataset\n",
    "p0, p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b5aea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is not recommended to use Maximum Likelihood method in classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f79f8",
   "metadata": {},
   "source": [
    "## Building the Markov Model\n",
    "\n",
    "The `Classifier` object below contains the methods to compute the log likelihoods and predict categories for new unseen text (lines of integers) based on the A and pi objects populated by the training data, as well as input from the log probabilities for class representation calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6e3e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier: \n",
    "    # The Constructor, which takes in the 'fitted' data and log priors and saves them as attributes of the object\n",
    "    def __init__(self, logAs, logpis, logpriors): \n",
    "        self.logAs = logAs \n",
    "        self.logpis = logpis \n",
    "        self.logpriors = logpriors \n",
    "        self.K = len(logpriors) # Number of classes (2)\n",
    "        \n",
    "    # Takes in line of integer text and class     \n",
    "    def _compute_log_likelihood(self, input_, class_):\n",
    "        logA = self.logAs[class_] \n",
    "        logpi = self.logpis[class_] \n",
    "        \n",
    "        last_idx = None \n",
    "        # logprob will hold the final answer\n",
    "        logprob = 0 \n",
    "        for idx in input_: \n",
    "            if last_idx is None: \n",
    "                # If previous word doesn't exist, it's the first token \n",
    "                logprob += logpi[idx]\n",
    "            else: \n",
    "                logprob += logA[last_idx, idx] \n",
    "                \n",
    "            # Update last_idx to current idx for next iteration \n",
    "            last_idx = idx \n",
    "            \n",
    "        return logprob\n",
    "    \n",
    "    # Takes in list of integer lines\n",
    "    def predict(self, inputs): \n",
    "        # Initialize variable to hold predicted classes\n",
    "        predictions = np.zeros(len(inputs)) \n",
    "        # Loop through each line and compute log likelihood for each\n",
    "        for i, input_ in enumerate(inputs): \n",
    "            posteriors = [self._compute_log_likelihood(input_, c) + self.logpriors[c] \\\n",
    "                          for c in range(self.K)]\n",
    "            pred = np.argmax(posteriors)\n",
    "            predictions[i] = pred \n",
    "            \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8356964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input is list of log(A)s, list of log(pi)s and list of log priors\n",
    "# Each array MUST BE IN ORDER of classes since the classes index the input lists (0, 1)\n",
    "\n",
    "clf = Classifier([logA0, logA1], [logpi0, logpi1], [logp0, logp1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8aaee753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9913473423980222\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy of classifier on training set, almost perfect as expected\n",
    "\n",
    "p_train = clf.predict(train_text_int)\n",
    "\n",
    "print(f\"Train accuracy: {np.mean(p_train == y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "404020e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7888888888888889\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy of classifier on test set ~ 78% (hmmm...but dataset is imbalanced)\n",
    "\n",
    "p_test = clf.predict(test_text_int)\n",
    "\n",
    "print(f\"Test accuracy: {np.mean(p_test == y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4ad95de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b39805fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 509,   14],\n",
       "       [   0, 1095]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 14 mis-labelled lines in training set\n",
    "\n",
    "cm_train = confusion_matrix(y_train, p_train)\n",
    "\n",
    "cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1dd39fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 91, 108],\n",
       "       [  6, 335]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 114 mis-labelled lines in test set\n",
    "\n",
    "cm_test = confusion_matrix(y_test, p_test)\n",
    "\n",
    "cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "286dd5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9936479128856625"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As expected, an almost perfect score\n",
    "f1_score(y_train, p_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c5ef36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8545918367346939"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1- score is quite good, so overall a sufficient text classifier - maybe there were a lot more unknown words\n",
    "\n",
    "f1_score(y_test, p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f2c35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
