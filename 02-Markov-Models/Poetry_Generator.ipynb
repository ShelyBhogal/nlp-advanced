{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "283ab754",
   "metadata": {},
   "source": [
    "# Text Generator\n",
    "\n",
    "Read in the Frost poetry text file to use in a **second-order Markov model**. This is an example of training the Markov model without matrices, but using dictionaries instead (dictionaries take up less space).\n",
    "\n",
    "Word probabilities will be stored in a dictionary, as stated, with the word as the key name or index attached to a probability value. In this example, you are not using any 'smoothing', like add-one smoothing, which means there will be a lot of zeros and those words will not be included in the dictionary at all.\n",
    "\n",
    "Use the 'trained' model to generate poems by Robert Frost (start with four lines at a time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a123dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "\n",
    "# Remove if you do not want reproducible results\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce2e5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = {} # First word of a sentence\n",
    "\n",
    "first_order = {} # Second word only\n",
    "\n",
    "second_order = {} # Word with at least two preceding words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d44b538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard function to remove punctuation in a line of text\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    return s.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "026a7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that takes in a dictionary, key and value to populate said dictionary with key and value, i.e. collect words\n",
    "\n",
    "def add2dict(d, k, v):\n",
    "    if k not in d:\n",
    "        d[k] = [] \n",
    "        d[k].append(v)\n",
    "\n",
    "# [cat, cat, dog, dog, dog, dog, mouse, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea7a545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Using functions above, traverse the lines in text file to populate the empty dictionaries created above.\n",
    "First tokenize the lines using the punctuation function, then loop through each word and add to: \n",
    "a) initial dictionary if it is the first word, and it doesn't exist in initial dictionary, add it and plus one to the word \n",
    " count if it does.\n",
    "b) second-order dictionary if it is the last word in a sentence (we don't want sentences to run on forever), add a fake 'END' \n",
    " token as the value with the 'previous word, current word' as the key.\n",
    "c) first-order dictionary if it is the second word given only one previous word, i.e. i == 1, where the previous word is the key\n",
    " and the current word is the value.\n",
    "d) second-order dictionary for any word with two preceding words, where previous words are the key and the current word is the \n",
    " value.\n",
    " \n",
    "NOTE: The only dictionary with actual word counts will be the initial dictionary.\n",
    "'''\n",
    "\n",
    "for line in open('data/robert_frost.txt'):\n",
    "    tokens = remove_punctuation(line.rstrip().lower()).split() \n",
    "    \n",
    "    T = len(tokens)\n",
    "    for i in range(T):\n",
    "        t = tokens[i] \n",
    "        if i == 0:\n",
    "            # Measure the counts of the first word\n",
    "            initial[t] = initial.get(t, 0.) + 1\n",
    "        else:\n",
    "            t_1 = tokens[i - 1]\n",
    "            \n",
    "            if i == T - 1:\n",
    "                # Add fake 'END' as value for word ending a line - (previous word, word) is the key\n",
    "                add2dict(second_order, (t_1, t), 'END')                \n",
    "            if i == 1:\n",
    "                # Measure counts of second word (given only previous word t_1)\n",
    "                add2dict(first_order, t_1, t)\n",
    "            else:\n",
    "                t_2 = tokens[i-2]\n",
    "                add2dict(second_order, (t_2, t_1), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9819e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the initial distribution (the only dictionary with word counts)\n",
    "\n",
    "initial_total = sum(initial.values())\n",
    "\n",
    "for t, c in initial.items():\n",
    "    initial[t] = c / initial_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "347aeb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'two': 0.005571030640668524,\n",
       " 'and': 0.08983286908077995,\n",
       " 'to': 0.034818941504178275}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(initial.items())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0081e626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'two': ['roads'], 'and': ['sorry'], 'to': ['where']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(first_order.items())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c42b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "{('two', 'roads'): ['diverged'],\n",
    " ('roads', 'diverged'): ['in'],\n",
    " ('diverged', 'in'): ['a']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88b0337d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('two', 'roads'): ['diverged'],\n",
       " ('roads', 'diverged'): ['in'],\n",
       " ('diverged', 'in'): ['a']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(second_order.items())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd97ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert input of list of words (tokens) into {'word1': 0.5, 'word2': 0.4, 'word3': 0.1}\n",
    "\n",
    "def list2pdict(ts):\n",
    "    d = {}\n",
    "    n = len(ts) \n",
    "    \n",
    "    # Find word count and add to value\n",
    "    for t in ts:\n",
    "        d[t] = d.get(t, 0.) + 1 \n",
    "    \n",
    "    # Find probability from word and count\n",
    "    for t, c in d.items():\n",
    "        d[t] = c / n \n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce2111ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace word value in first_order dictionary to nested dictionary of word and probability\n",
    "\n",
    "for t_1, ts in first_order.items(): \n",
    "    first_order[t_1] = list2pdict(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "502719fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'two': {'roads': 1.0}, 'and': {'sorry': 1.0}, 'to': {'where': 1.0}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(first_order.items())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78a3a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace word value in second_order dictionary to nested dictionary of word and probability\n",
    "\n",
    "for k, ts in second_order.items():\n",
    "    second_order[k] = list2pdict(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e5898b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('two', 'roads'): {'diverged': 1.0},\n",
       " ('roads', 'diverged'): {'in': 1.0},\n",
       " ('diverged', 'in'): {'a': 1.0}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(second_order.items())[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6cb59c",
   "metadata": {},
   "source": [
    "**Now your dictionaries are ready to be randomly sampled from when generating lines of a poem.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9490558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to randomly sample words from a dictionary based on uniform distribution\n",
    "\n",
    "def sample_word(d):\n",
    "    # Draw random number between 0 and 1 (Print \"d:\", d) \n",
    "    p0 = np.random.random() \n",
    "    \n",
    "    # Store the cumulative probabilities (Print \"p0:\", p0) \n",
    "    cumulative = 0 \n",
    "    \n",
    "    # Loop through tokens and probability values and increment cumulative sum\n",
    "    for t, p in d.items():\n",
    "        cumulative += p \n",
    "        if p0 < cumulative:\n",
    "            return t \n",
    "        \n",
    "    assert(False) # Should never get here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "363eef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    for i in range(4): # Run loop 4 times (for 4 lines of the poem) \n",
    "        sentence = [] \n",
    "        \n",
    "        # Sample one word from initial dictionary \n",
    "        w0 = sample_word(initial) \n",
    "        sentence.append(w0)\n",
    "        \n",
    "        # Sample one second word based on initial word (nested key under initial word)\n",
    "        w1 = sample_word(first_order[w0]) \n",
    "        sentence.append(w1)\n",
    "        \n",
    "        # Sample second-order words until 'END' (infinite loop)\n",
    "        while True:\n",
    "            w2 = sample_word(second_order[(w0, w1)]) \n",
    "            if w2 == 'END':\n",
    "                break         \n",
    "            sentence.append(w2) \n",
    "            w0 = w1 \n",
    "            w1 = w2 \n",
    "        \n",
    "        # Print tokens in single line by joining them\n",
    "        print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e403d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "though as for that the passing there\n",
      "ill double theirs for both of them all aglitter\n",
      "the darkest evening of the year\n",
      "for hog reeve in march meeting here in warren\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ef92c3",
   "metadata": {},
   "source": [
    "# Exercise 1:\n",
    "\n",
    "### Determine the vocabulary size (V)\n",
    "\n",
    "Use the method from text classifier session to create a vocabulary of words from the Robert Frost text data (word-to-index mapping dictionary).\n",
    "\n",
    "### We know that pi has shape V, A1 has shape V x V, and A2 has shape V x V x V (full-dense arrays). In comparison, how many values are stored in our dictionaries?\n",
    "\n",
    "This should demonstrate the advantage of using dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ebb32",
   "metadata": {},
   "source": [
    "# Exercise 2:\n",
    "\n",
    "You can skip the step where you accumulate all the possible next words in a list, i.e. first and second-order dictionaries, \n",
    "\n",
    "e.g. [cat, cat, dog, dog, dog, ...]\n",
    "\n",
    "Instead, like with initial state distribution, create the dictionary of counts directly as you loop through the data (you will no longer need `list2pdict()` function)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
