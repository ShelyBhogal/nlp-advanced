{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "373aa979",
   "metadata": {},
   "source": [
    "You can download the .gz file containing the **pre-trained word embeddings** from the following source:\n",
    "\n",
    "`!wget -nc https://lazyprogrammer.me/course_files/nlp/GoogleNews-vectors-negative300.bin.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4948b",
   "metadata": {},
   "source": [
    "The terminal command line below unzips the .gz file, and only needs to be run once. The bin folder should be extracted to the same folder as this notebook. For Windows users, however, you need to use *7-Zip* tool to extract the folder.\n",
    "\n",
    "`tar -xvzf .\\GoogleNews-vectors-negative300.bin.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f84bc4",
   "metadata": {},
   "source": [
    "The bin folder contains pre-trained word embeddings in a **bin file**, and it is more common than you think that you will use word embeddings trained by someone else, since training a neural network takes a lot of resources and time. The downloaded model contains 300-dimensional vectors for 3 million words and phrases. **Gensim** library is the go-to library for word embeddings in NLP, and the `KeyedVectors` class allows you to load the pre-trained vectors and query them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7704b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5db5e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained word vectors\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format(\n",
    "    'data/GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin', \n",
    "    binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dacf03",
   "metadata": {},
   "source": [
    "# Finding word analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6104e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogies(w1, w2, w3): \n",
    "    # w1 - w2 = ? - w3 \n",
    "    # e.g. king - man = ? - woman \n",
    "    #      ? = +king +woman -man \n",
    "    \n",
    "    r = word_vectors.most_similar(positive=[w1, w3], negative=[w2]) \n",
    "    print(\"%s - %s = %s - %s\" % (w1, w2, r[0][0], w3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca5023ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king - man = queen - woman\n"
     ]
    }
   ],
   "source": [
    "find_analogies('king', 'man', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3add70ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france - paris = england - london\n"
     ]
    }
   ],
   "source": [
    "find_analogies('france', 'paris', 'london')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9212be2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france - paris = italy - rome\n"
     ]
    }
   ],
   "source": [
    "find_analogies('france', 'paris', 'rome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c55567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris - france = lohan - italy\n"
     ]
    }
   ],
   "source": [
    "# If you reverse country-city to city-county it should work regardless\n",
    "# This indicates word vectors are not perfectly associated\n",
    "\n",
    "find_analogies('paris', 'france', 'italy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edbb9cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france - french = england - english\n"
     ]
    }
   ],
   "source": [
    "find_analogies('france', 'french', 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "662e2570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japan - japanese = tibet - chinese\n"
     ]
    }
   ],
   "source": [
    "# Obviously the answer should be 'china' instead of 'tibet'\n",
    "# Again indicates the word vectors most closely-related are not correct\n",
    "\n",
    "find_analogies('japan', 'japanese', 'chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "638c373b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japan - japanese = italy - italian\n"
     ]
    }
   ],
   "source": [
    "find_analogies('japan', 'japanese', 'italian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "602d47af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "december - november = september - june\n"
     ]
    }
   ],
   "source": [
    "# Expected 'may' as the previous month in logic, but at least we still got a month\n",
    "# Note that GloVe has more success with this type of thing\n",
    "\n",
    "find_analogies('december', 'november', 'june')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7fd4b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miami - florida = dallas - texas\n"
     ]
    }
   ],
   "source": [
    "find_analogies('miami', 'florida', 'texas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83782cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "einstein - scientist = jude - painter\n"
     ]
    }
   ],
   "source": [
    "# Expected answer like 'picasso' or 'rembrandt' - who is Jude???\n",
    "\n",
    "find_analogies('einstein', 'scientist', 'painter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6bd8647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man - woman = he - she\n"
     ]
    }
   ],
   "source": [
    "find_analogies('man', 'woman', 'she')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0e60645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man - woman = uncle - aunt\n"
     ]
    }
   ],
   "source": [
    "find_analogies('man', 'woman', 'aunt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d922280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man - woman = brother - sister\n"
     ]
    }
   ],
   "source": [
    "find_analogies('man', 'woman', 'sister')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3731a1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man - woman = son - wife\n"
     ]
    }
   ],
   "source": [
    "# Oops! Should be 'husband', not 'son'! These vectors are not perfect, maybe 'husband' is not top result...\n",
    "\n",
    "find_analogies('man', 'woman', 'wife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9889e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man - woman = actor - actress\n"
     ]
    }
   ],
   "source": [
    "find_analogies('man', 'woman', 'actress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aade3cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man - woman = father - mother\n"
     ]
    }
   ],
   "source": [
    "find_analogies('man', 'woman', 'mother')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "194d82e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nephew - niece = uncle - aunt\n"
     ]
    }
   ],
   "source": [
    "find_analogies('nephew', 'niece', 'aunt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55be85a",
   "metadata": {},
   "source": [
    "# Finding similar words\n",
    "\n",
    "This is simpler function compared to the one used for word analogies - just finding the most similar words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2dc585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a word, what are the most similar words?\n",
    "\n",
    "def nearest_neighbors(w): \n",
    "    r = word_vectors.most_similar(positive=[w]) \n",
    "    print(\"neighbors of: %s\" % w) \n",
    "    \n",
    "    # Loop through results to extract words only\n",
    "    for word, score in r: \n",
    "        print(\"\\t%s\" % word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dab5e1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: king\n",
      "\tkings\n",
      "\tqueen\n",
      "\tmonarch\n",
      "\tcrown_prince\n",
      "\tprince\n",
      "\tsultan\n",
      "\truler\n",
      "\tprinces\n",
      "\tPrince_Paras\n",
      "\tthrone\n"
     ]
    }
   ],
   "source": [
    "nearest_neighbors('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1547e3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: france\n",
      "\tspain\n",
      "\tfrench\n",
      "\tgermany\n",
      "\teurope\n",
      "\titaly\n",
      "\tengland\n",
      "\teuropean\n",
      "\tbelgium\n",
      "\tusa\n",
      "\tserbia\n"
     ]
    }
   ],
   "source": [
    "nearest_neighbors('france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8abbf2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: japan\n",
      "\tjapanese\n",
      "\ttokyo\n",
      "\tamerica\n",
      "\teurope\n",
      "\tgermany\n",
      "\tchinese\n",
      "\tindia\n",
      "\thawaii\n",
      "\tusa\n",
      "\tkorea\n"
     ]
    }
   ],
   "source": [
    "# Where is 'tibet'???\n",
    "\n",
    "nearest_neighbors('japan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f248ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: einstein\n",
      "\tnikki\n",
      "\tlmfao\n",
      "\talbert\n",
      "\tarmstrong\n",
      "\tjoan\n",
      "\tbecky\n",
      "\tmcmahon\n",
      "\tconrad\n",
      "\tlori\n",
      "\thaley\n"
     ]
    }
   ],
   "source": [
    "# Hmmm! Maybe too many people use 'einstein' sarcastically\n",
    "\n",
    "nearest_neighbors('einstein')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "551838de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: woman\n",
      "\tman\n",
      "\tgirl\n",
      "\tteenage_girl\n",
      "\tteenager\n",
      "\tlady\n",
      "\tteenaged_girl\n",
      "\tmother\n",
      "\tpolicewoman\n",
      "\tboy\n",
      "\tWoman\n"
     ]
    }
   ],
   "source": [
    "nearest_neighbors('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ee75c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: nephew\n",
      "\tson\n",
      "\tuncle\n",
      "\tbrother\n",
      "\tgrandson\n",
      "\tcousin\n",
      "\tfather\n",
      "\tniece\n",
      "\tyounger_brother\n",
      "\tnephews\n",
      "\tstepson\n"
     ]
    }
   ],
   "source": [
    "nearest_neighbors('nephew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "968cf267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: february\n",
      "\tjanuary\n",
      "\tapril\n",
      "\tseptember\n",
      "\tdecember\n",
      "\tjuly\n",
      "\toctober\n",
      "\tnovember\n",
      "\tjune\n",
      "\tfeb\n",
      "\tnorway\n"
     ]
    }
   ],
   "source": [
    "# Hmmm! All other months except for 'norway'...\n",
    "\n",
    "nearest_neighbors('february')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053794d9",
   "metadata": {},
   "source": [
    "**EXERCISE: Download pre-trained GloVe vectors glove.6B.zip from https://nlp.stanford.edu/projects/glove/.**\n",
    "\n",
    "* **Implement your own `find_analogies()` and `nearest_neighbors()` custom functions**\n",
    "\n",
    "**HINT:** you do NOT have to go hunting around on StackOverflow, you do NOT have to copy-and-paste code from anywhere external, and make sure to look at the file you downloaded.\n",
    "\n",
    "**NOTE:** The GloVe pre-trained embeddings is an 822 MB zip file with 4 different models (50, 100, 200 and 300-dimensional vectors) trained on Wikipedia data with 6 billion tokens and a 400,000 word vocabulary. It is a large file to download so make sure you have space on your computer. If you successfully download the text file, you can run the word analogy and nearest neighbour functions on each vector space (50, 100, 200 and 300) to observe the differences between Word2Vec and GloVe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923fe91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove.6B.zip TOO LARGE TO DOWNLOAD! MAKE SPACE IN STORAGE\n",
    "\n",
    "\n",
    "# <-- Copied-and-pasted from online -->\n",
    "\n",
    "# Convert txt file to word2vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_input_file = 'data/glove.6B.100d.txt'\n",
    "word2vec_output_file = 'data/glove.6B.100d.txt.word2vec'\n",
    "\n",
    "# Convert GloVe model to Word2vec model\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5500306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Stanford GloVe model using same KeyedVectors class but ensure binary is False\n",
    "model = KeyedVectors.load_word2vec_format('data/glove.6B.100d.txt.word2vec', binary=False)\n",
    "\n",
    "# Calculate: (king - man) + woman = ? analogy\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40d7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find analogies with converted GloVe model\n",
    "\n",
    "def find_analogies(w1, w2, w3): \n",
    "    # w1 - w2 = ? - w3 \n",
    "    # e.g. king - man = ? - woman \n",
    "    #      ? = +king +woman -man \n",
    "    \n",
    "    r = model.most_similar(positive=[w1, w3], negative=[w2]) \n",
    "    print(\"%s - %s = %s - %s\" % (w1, w2, r[0][0], w3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
